{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d5bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer1.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer2.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer3.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.downsample.0.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.downsample.1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.0.downsample.1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.conv1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.conv2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/Users/andresmauriciotrianareina/miniconda3/envs/PruebaXolit/lib/python3.12/site-packages/torch/nn/modules/module.py:2446: UserWarning: for layer4.1.bn2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at microsoft/table-transformer-detection were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Extracto - Diciembre  2025.pdf | pages=7 | render=plain | bank=Banco de Bogot√° | last4=0193 | year=2025\n",
      "  - page 1: tablas_detectadas=1 (thr=0.4/0.3)\n",
      "    table 1: score=1.00 bbox=(115, 1414, 2455, 3006)\n",
      "      header: Fecha a Descripci√≥n del Movimiento Ciudad Oficina/Canal Documento Valor Saldo\n",
      "      col_map: {'date': 0, 'description': 2, 'location': 3, 'channel': 4, 'reference': 5, 'amount': 6, 'balance': 7}\n",
      "      rows(after header)=42 kept=42 cont=0 skipped_no_amount=0\n",
      "  - page 2: tablas_detectadas=1 (thr=0.4/0.3)\n",
      "    table 1: score=1.00 bbox=(227, 325, 2501, 3175)\n",
      "      ‚ùå No header detected\n",
      "  - page 3: tablas_detectadas=1 (thr=0.4/0.3)\n",
      "    table 1: score=1.00 bbox=(226, 326, 2502, 3166)\n",
      "      ‚ùå No header detected\n",
      "  - page 4: tablas_detectadas=1 (thr=0.4/0.3)\n",
      "    table 1: score=0.99 bbox=(229, 325, 2503, 3173)\n",
      "      ‚ùå No header detected\n",
      "  - page 5: tablas_detectadas=1 (thr=0.4/0.3)\n",
      "    table 1: score=1.00 bbox=(229, 327, 2504, 3170)\n",
      "      ‚ùå No header detected\n",
      "  - page 6: tablas_detectadas=1 (thr=0.4/0.3)\n",
      "    table 1: score=1.00 bbox=(226, 327, 2502, 3168)\n",
      "      header: 23/12 0016 |Retiro cajero automatico ATH Banco de Bogota 0521 Canal Electro 0004440 -600,000.00 170,967,792.62\n",
      "      col_map: {'reference': 2, 'channel': 3}\n",
      "      rows(after header)=16 kept=13 cont=3 skipped_no_amount=0\n",
      "  - page 7: tablas_detectadas=1 (thr=0.4/0.3)\n",
      "    table 1: score=1.00 bbox=(225, 324, 2502, 3175)\n",
      "      ‚ùå No header detected\n",
      "  => total tablas detectadas en PDF: 7 | filas_kept_pdf=55\n",
      "\n",
      "‚úÖ Excel generado: extractos_full_20260126_134226.xlsx\n",
      "RESUMEN: {'pdfs': 1, 'rows': 55}\n"
     ]
    }
   ],
   "source": [
    "# %% (IPYNB - UNA SOLA CELDA) ‚Äî MEJORADO: menos p√©rdida, d√©bito/cr√©dito, fecha robusta, prints\n",
    "import os, re, glob, uuid, tempfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, TableTransformerForObjectDetection\n",
    "\n",
    "# ===========================\n",
    "# CONFIG\n",
    "# ===========================\n",
    "PDF_DIR = '/Users/andresmauriciotrianareina/Downloads/pdf'\n",
    "OUTPUT_XLSX = f\"extractos_full_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "\n",
    "PASSWORDS: List[str] = [\"1030581154\"]\n",
    "MAX_PAGES = None\n",
    "DPI = 300\n",
    "LANG_OCR = \"spa+eng\"\n",
    "\n",
    "DEFAULT_BANK = \"Banco\"\n",
    "DEFAULT_CURRENCY = \"COP\"\n",
    "\n",
    "TABLE_DET_MODEL = \"microsoft/table-transformer-detection\"\n",
    "\n",
    "# M√°s permisivo para no perder tablas\n",
    "DETECTION_SCORE_THRESHOLD = 0.40   # <-- antes 0.50, ahora m√°s recall\n",
    "SECONDARY_THRESHOLD = 0.30         # <-- si no detecta nada, baja m√°s\n",
    "\n",
    "# OCR config\n",
    "TESS_CONFIG = \"--psm 6\"\n",
    "\n",
    "# Debug\n",
    "DEBUG_TABLES = True\n",
    "DEBUG_SHOW_SAMPLES = 2   # muestra 2 filas ‚Äúskipped‚Äù por tabla\n",
    "\n",
    "# ===========================\n",
    "# HEADERS / SIN√ìNIMOS\n",
    "# ===========================\n",
    "HEADER_SYNONYMS = {\n",
    "    \"date\": [\"fecha\", \"date\", \"fec\", \"fecha mov\", \"fecha movimiento\"],\n",
    "    \"time\": [\"hora\", \"time\"],\n",
    "    # ojo: \"amount\" general, pero tambi√©n manejaremos DEBIT/CREDIT aparte\n",
    "    \"amount\": [\"valor\", \"value\", \"amount\", \"importe\", \"monto\", \"total\", \"transacci√≥n\", \"transaccion\"],\n",
    "    \"debit\": [\"debito\", \"d√©bito\", \"cargo\", \"retiro\", \"egreso\", \"salida\", \"dr\"],\n",
    "    \"credit\": [\"credito\", \"cr√©dito\", \"abono\", \"ingreso\", \"entrada\", \"cr\"],\n",
    "    \"description\": [\"descripcion\", \"descripci√≥n\", \"description\", \"movimiento\", \"movimientos\", \"clase de movimiento\", \"detalle\", \"concepto\"],\n",
    "    \"reference\": [\"documento\", \"doc\", \"ref\", \"referencia\", \"cod\", \"cod trans\", \"c√≥d trans\", \"n√∫mero\", \"numero\", \"no.\", \"num\", \"nro\", \"trans\", \"codtrans\", \"aut\", \"autoriz\"],\n",
    "    \"location\": [\"ciudad\", \"city\", \"lugar\"],\n",
    "    \"channel\": [\"oficina\", \"canal\", \"oficina/canal\", \"channel\", \"sucursal\", \"app\", \"cajero\"],\n",
    "    \"balance\": [\"saldo\", \"balance\", \"sldo\", \"saldo disponible\", \"saldo total\"],\n",
    "}\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip().lower())\n",
    "\n",
    "def _contains_any(text: str, keys: List[str]) -> bool:\n",
    "    t = _norm(text)\n",
    "    return any(k in t for k in keys)\n",
    "\n",
    "# ===========================\n",
    "# EXCEL: limpiar chars ilegales (NO TRUNCA, solo control chars)\n",
    "# ===========================\n",
    "_ILLEGAL_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]\")\n",
    "\n",
    "def sanitize_excel_str(x: Any) -> Any:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    if isinstance(x, (int, float)):\n",
    "        return x\n",
    "    s = str(x)\n",
    "    s = s.replace(\"\\u0000\", \" \")\n",
    "    s = _ILLEGAL_RE.sub(\" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# ===========================\n",
    "# BANCO + LAST4\n",
    "# ===========================\n",
    "def detect_bank_and_last4(text: str) -> Tuple[str, str]:\n",
    "    t = _norm(text)\n",
    "    bank = DEFAULT_BANK\n",
    "    if \"banco de bogot√°\" in t or \"banco de bogota\" in t: bank = \"Banco de Bogot√°\"\n",
    "    elif \"bancolombia\" in t: bank = \"Bancolombia\"\n",
    "    elif \"davivienda\" in t: bank = \"Davivienda\"\n",
    "    elif \"bbva\" in t: bank = \"BBVA\"\n",
    "    last4 = \"\"\n",
    "    m = re.search(r\"(?:cuenta|account|cta|tarjeta|card).{0,80}?(\\d{4})\\b\", text, re.IGNORECASE)\n",
    "    if m: last4 = m.group(1)\n",
    "    return bank, last4\n",
    "\n",
    "# ===========================\n",
    "# MOVEMENT TYPE\n",
    "# ===========================\n",
    "def classify_movement_type(description: str) -> str:\n",
    "    d = _norm(description)\n",
    "    rules = [\n",
    "        (\"cdt\", [\"cdt\", \"certificado de deposito\", \"certificado de dep√≥sito\", \"t√≠tulo\", \"titulo\"]),\n",
    "        (\"intereses\", [\"interes\", \"inter√©s\", \"rendimiento\", \"rendimientos\"]),\n",
    "        (\"impuesto\", [\"gmf\", \"4x1000\", \"impuesto\", \"retencion\", \"retenci√≥n\", \"iva\"]),\n",
    "        (\"retiro\", [\"retiro\", \"atm\", \"cajero\", \"withdrawal\"]),\n",
    "        (\"transferencia\", [\"transferencia\", \"transf\", \"pse\", \"ach\", \"envio\", \"env√≠o\"]),\n",
    "        (\"pago\", [\"pago\", \"cuota\", \"tarj\", \"tarjeta\", \"credito\", \"cr√©dito\", \"servicio\", \"manejo\"]),\n",
    "        (\"compra\", [\"compra\", \"pos\", \"dat√°fono\", \"datafono\", \"comercio\", \"apple.com\", \"bill\", \"supermercado\", \"mercado\"]),\n",
    "        (\"abono\", [\"abono\", \"consignacion\", \"consignaci√≥n\", \"deposito\", \"dep√≥sito\", \"ingreso\", \"recaudo\"]),\n",
    "    ]\n",
    "    for label, kws in rules:\n",
    "        if any(k in d for k in kws): return label\n",
    "    return \"pago\"\n",
    "\n",
    "# ===========================\n",
    "# MONEDA + MONTO ROBUSTO\n",
    "# ===========================\n",
    "CURRENCY_HINTS = {\n",
    "    \"USD\": [\"usd\", \"us$\", \"u$s\", \"dolar\", \"d√≥lar\", \"dollars\"],\n",
    "    \"COP\": [\"cop\", \"peso\", \"pesos\", \"col$\"],\n",
    "}\n",
    "\n",
    "def infer_currency(text: str, default: str = \"COP\") -> str:\n",
    "    t = _norm(text)\n",
    "    if any(k in t for k in CURRENCY_HINTS[\"USD\"]): return \"USD\"\n",
    "    if any(k in t for k in CURRENCY_HINTS[\"COP\"]): return \"COP\"\n",
    "    return default\n",
    "\n",
    "def parse_amount_string(raw: str) -> Optional[float]:\n",
    "    if raw is None:\n",
    "        return None\n",
    "    s = str(raw).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "\n",
    "    neg = False\n",
    "    if re.search(r\"(^\\s*-\\s*)|(\\(\\s*)\", s):\n",
    "        neg = True\n",
    "\n",
    "    s2 = re.sub(r\"[^\\d,.\\-()]\", \"\", s)\n",
    "    s2 = s2.replace(\"(\", \"\").replace(\")\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "    if not re.search(r\"\\d\", s2):\n",
    "        return None\n",
    "\n",
    "    comma = \",\" in s2\n",
    "    dot = \".\" in s2\n",
    "\n",
    "    if comma and dot:\n",
    "        last_comma = s2.rfind(\",\")\n",
    "        last_dot = s2.rfind(\".\")\n",
    "        if last_dot > last_comma:\n",
    "            s2 = s2.replace(\",\", \"\")\n",
    "        else:\n",
    "            s2 = s2.replace(\".\", \"\")\n",
    "            s2 = s2.replace(\",\", \".\")\n",
    "    elif comma and not dot:\n",
    "        if re.search(r\",\\d{1,2}$\", s2):\n",
    "            s2 = s2.replace(\",\", \".\")\n",
    "        else:\n",
    "            s2 = s2.replace(\",\", \"\")\n",
    "    elif dot and not comma:\n",
    "        if not re.search(r\"\\.\\d{1,2}$\", s2):\n",
    "            s2 = s2.replace(\".\", \"\")\n",
    "\n",
    "    try:\n",
    "        val = float(s2)\n",
    "        return -val if neg else val\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_amount_and_currency(amount_cell: str, desc: str, default_currency: str = \"COP\") -> Tuple[Optional[float], str]:\n",
    "    cur = infer_currency((amount_cell or \"\") + \" \" + (desc or \"\"), default=default_currency)\n",
    "    amt = parse_amount_string(amount_cell)\n",
    "    return amt, cur\n",
    "\n",
    "# Extra: si no hay amount column clara, busca montos en texto\n",
    "AMT_FALLBACK_RE = re.compile(r\"(?<!\\w)(\\(?-?\\$?\\s*\\d{1,3}(?:[.,\\s]\\d{3})*(?:[.,]\\d{1,2})?\\)?)(?!\\w)\")\n",
    "\n",
    "def parse_amount_from_text_fallback(row_text: str) -> Optional[float]:\n",
    "    cands = AMT_FALLBACK_RE.findall(row_text or \"\")\n",
    "    if not cands:\n",
    "        return None\n",
    "    # usualmente el √∫ltimo n√∫mero grande de la l√≠nea es el monto del movimiento\n",
    "    # preferimos el candidato con m√°s d√≠gitos\n",
    "    cands_sorted = sorted(cands, key=lambda s: (len(re.sub(r\"\\D\", \"\", s)), (row_text.rfind(s))), reverse=True)\n",
    "    for c in cands_sorted[:5]:\n",
    "        v = parse_amount_string(c)\n",
    "        if v is not None and abs(v) >= 0.01:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "# ===========================\n",
    "# FECHAS\n",
    "# ===========================\n",
    "MONTHS_ES = {\n",
    "    \"ene\":1,\"enero\":1,\"feb\":2,\"febrero\":2,\"mar\":3,\"marzo\":3,\"abr\":4,\"abril\":4,\"may\":5,\"mayo\":5,\n",
    "    \"jun\":6,\"junio\":6,\"jul\":7,\"julio\":7,\"ago\":8,\"agosto\":8,\"sep\":9,\"sept\":9,\"septiembre\":9,\n",
    "    \"oct\":10,\"octubre\":10,\"nov\":11,\"noviembre\":11,\"dic\":12,\"diciembre\":12,\n",
    "}\n",
    "\n",
    "def infer_statement_year(text: str) -> Optional[int]:\n",
    "    t = text or \"\"\n",
    "    m = re.search(r\"(periodo|per√≠odo|extracto|mes)\\D{0,40}((19|20)\\d{2})\", t, re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(2))\n",
    "    m = re.search(r\"(ene|enero|feb|febrero|mar|marzo|abr|abril|may|mayo|jun|junio|jul|julio|ago|agosto|sep|sept|septiembre|oct|octubre|nov|noviembre|dic|diciembre)\\D{0,10}((19|20)\\d{2})\", t, re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(2))\n",
    "    years = re.findall(r\"\\b(19\\d{2}|20\\d{2})\\b\", t)\n",
    "    if years:\n",
    "        from collections import Counter\n",
    "        y = Counter(years).most_common(1)[0][0]\n",
    "        return int(y)\n",
    "    return None\n",
    "\n",
    "def normalize_date_str(date_raw: str, statement_year: Optional[int]) -> str:\n",
    "    if not date_raw:\n",
    "        return \"\"\n",
    "    s = str(date_raw).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "\n",
    "    s_clean = s.replace(\"\\\\\", \"/\").replace(\"-\", \"/\")\n",
    "    s_clean = re.sub(r\"\\s+\", \" \", s_clean).strip()\n",
    "\n",
    "    m = re.search(r\"\\b(\\d{1,2})\\s*/\\s*(\\d{1,2})(?:\\s*/\\s*(\\d{2,4}))?\\b\", s_clean)\n",
    "    if m:\n",
    "        d = int(m.group(1))\n",
    "        mo = int(m.group(2))\n",
    "        y = m.group(3)\n",
    "        if y:\n",
    "            y = int(y)\n",
    "            if y < 100: y += 2000\n",
    "        else:\n",
    "            y = statement_year\n",
    "        if y:\n",
    "            try:\n",
    "                return pd.Timestamp(year=y, month=mo, day=d).date().isoformat()\n",
    "            except:\n",
    "                return \"\"\n",
    "\n",
    "    m = re.search(r\"\\b(\\d{1,2})\\s+(\\d{1,2})\\b\", s_clean)\n",
    "    if m and not re.search(r\"\\d{1,2}:\\d{2}\", s_clean):\n",
    "        d = int(m.group(1)); mo = int(m.group(2)); y = statement_year\n",
    "        if y:\n",
    "            try:\n",
    "                return pd.Timestamp(year=y, month=mo, day=d).date().isoformat()\n",
    "            except:\n",
    "                return \"\"\n",
    "\n",
    "    s2 = _norm(s_clean)\n",
    "    m = re.search(r\"\\b(\\d{1,2})\\s*(ene|enero|feb|febrero|mar|marzo|abr|abril|may|mayo|jun|junio|jul|julio|ago|agosto|sep|sept|septiembre|oct|octubre|nov|noviembre|dic|diciembre)\\s*((19|20)\\d{2})?\\b\", s2)\n",
    "    if m:\n",
    "        d = int(m.group(1))\n",
    "        mo = MONTHS_ES.get(m.group(2), None)\n",
    "        y = int(m.group(3)) if m.group(3) else statement_year\n",
    "        if mo and y:\n",
    "            try:\n",
    "                return pd.Timestamp(year=y, month=mo, day=d).date().isoformat()\n",
    "            except:\n",
    "                return \"\"\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "# Fallback: si date cell falla, buscar fecha en la fila completa\n",
    "DATE_FALLBACK_RE = re.compile(r\"\\b(\\d{1,2}\\s*/\\s*\\d{1,2}(?:\\s*/\\s*\\d{2,4})?)\\b\")\n",
    "\n",
    "def date_from_row_fallback(row_txt: str, statement_year: Optional[int]) -> str:\n",
    "    if not row_txt:\n",
    "        return \"\"\n",
    "    m = DATE_FALLBACK_RE.search(row_txt)\n",
    "    if m:\n",
    "        return normalize_date_str(m.group(1), statement_year)\n",
    "    # caso ‚Äú24Ene‚Äù etc\n",
    "    m2 = re.search(r\"\\b(\\d{1,2})\\s*(ene|enero|feb|febrero|mar|marzo|abr|abril|may|mayo|jun|junio|jul|julio|ago|agosto|sep|sept|septiembre|oct|octubre|nov|noviembre|dic|diciembre)\\b\", _norm(row_txt))\n",
    "    if m2:\n",
    "        return normalize_date_str(m2.group(0), statement_year)\n",
    "    return \"\"\n",
    "\n",
    "# ===========================\n",
    "# PDF ENCRIPTACI√ìN -> RENDER\n",
    "# ===========================\n",
    "def decrypt_pdf_to_tempfile(pdf_path: str, passwords: List[str]) -> Tuple[Optional[str], Optional[str], str]:\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        if not reader.is_encrypted:\n",
    "            return pdf_path, None, \"\"\n",
    "        used = None\n",
    "        opened = False\n",
    "        for pw in passwords:\n",
    "            try:\n",
    "                r2 = PdfReader(pdf_path)\n",
    "                ok = r2.decrypt(pw)\n",
    "                if ok:\n",
    "                    reader = r2\n",
    "                    used = pw\n",
    "                    opened = True\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "        if not opened:\n",
    "            return None, None, \"No se pudo abrir el PDF con PASSWORDS.\"\n",
    "\n",
    "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n",
    "        tmp_path = tmp.name\n",
    "        tmp.close()\n",
    "\n",
    "        writer = PdfWriter()\n",
    "        for p in reader.pages:\n",
    "            writer.add_page(p)\n",
    "        with open(tmp_path, \"wb\") as f:\n",
    "            writer.write(f)\n",
    "        return tmp_path, used, \"\"\n",
    "    except Exception as e:\n",
    "        return None, None, f\"decrypt_tempfile error: {type(e).__name__}: {e}\"\n",
    "\n",
    "def render_pdf_pages(pdf_path: str, passwords: List[str], dpi: int, max_pages: Optional[int]) -> Tuple[List[Image.Image], Optional[str], str]:\n",
    "    try:\n",
    "        pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "        if max_pages: pages = pages[:max_pages]\n",
    "        return pages, None, \"plain\"\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for pw in passwords:\n",
    "        try:\n",
    "            pages = convert_from_path(pdf_path, dpi=dpi, userpw=pw)\n",
    "            if max_pages: pages = pages[:max_pages]\n",
    "            return pages, pw, \"userpw\"\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    tmp_path, used_pw, err = decrypt_pdf_to_tempfile(pdf_path, passwords)\n",
    "    if err or not tmp_path:\n",
    "        return [], None, \"fail\"\n",
    "\n",
    "    try:\n",
    "        pages = convert_from_path(tmp_path, dpi=dpi)\n",
    "        if max_pages: pages = pages[:max_pages]\n",
    "        return pages, used_pw, \"tmp\"\n",
    "    finally:\n",
    "        try:\n",
    "            if tmp_path != pdf_path and Path(tmp_path).exists():\n",
    "                os.remove(tmp_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# ===========================\n",
    "# TABLE DETECTOR (CPU)\n",
    "# ===========================\n",
    "device = torch.device(\"cpu\")\n",
    "processor = AutoImageProcessor.from_pretrained(TABLE_DET_MODEL)\n",
    "model = TableTransformerForObjectDetection.from_pretrained(TABLE_DET_MODEL).to(device)\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def detect_tables(pil_img: Image.Image, score_thr=0.40) -> List[Dict[str, Any]]:\n",
    "    inputs = processor(images=pil_img, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    target_sizes = torch.tensor([pil_img.size[::-1]])\n",
    "    res = processor.post_process_object_detection(outputs, threshold=score_thr, target_sizes=target_sizes)[0]\n",
    "    out = []\n",
    "    for score, box in zip(res[\"scores\"], res[\"boxes\"]):\n",
    "        x0, y0, x1, y1 = [int(v) for v in box.tolist()]\n",
    "        out.append({\"bbox\": (x0,y0,x1,y1), \"score\": float(score)})\n",
    "    out.sort(key=lambda d: (d[\"score\"], (d[\"bbox\"][2]-d[\"bbox\"][0])*(d[\"bbox\"][3]-d[\"bbox\"][1])), reverse=True)\n",
    "    return out\n",
    "\n",
    "def pad_bbox(bbox, w, h, pad=18):\n",
    "    x0,y0,x1,y1 = bbox\n",
    "    x0 = max(0, x0-pad); y0 = max(0, y0-pad)\n",
    "    x1 = min(w, x1+pad); y1 = min(h, y1+pad)\n",
    "    return (x0,y0,x1,y1)\n",
    "\n",
    "# ===========================\n",
    "# OCR STRUCTURED\n",
    "# ===========================\n",
    "def ocr_data_df(img: Image.Image) -> pd.DataFrame:\n",
    "    d = pytesseract.image_to_data(img, lang=LANG_OCR, output_type=pytesseract.Output.DATAFRAME, config=TESS_CONFIG)\n",
    "    d = d.dropna(subset=[\"text\"])\n",
    "    d[\"text\"] = d[\"text\"].astype(str)\n",
    "    d = d[(d[\"text\"].str.strip() != \"\") & (d[\"conf\"] > 0)]\n",
    "    return d\n",
    "\n",
    "def cluster_rows(words: pd.DataFrame) -> pd.DataFrame:\n",
    "    if words.empty:\n",
    "        words[\"row_id\"] = []\n",
    "        return words\n",
    "    w = words.copy()\n",
    "    w[\"y_mid\"] = w[\"top\"] + (w[\"height\"]/2.0)\n",
    "    w = w.sort_values([\"y_mid\",\"left\"]).reset_index(drop=True)\n",
    "    h_med = float(w[\"height\"].median()) if len(w) else 10.0\n",
    "    thr = max(6.0, 0.75*h_med)\n",
    "    row_ids = []\n",
    "    cur = 0\n",
    "    prev_y = None\n",
    "    for ym in w[\"y_mid\"].tolist():\n",
    "        if prev_y is None:\n",
    "            row_ids.append(cur); prev_y = ym; continue\n",
    "        if abs(ym-prev_y) > thr:\n",
    "            cur += 1; prev_y = ym\n",
    "        row_ids.append(cur)\n",
    "    w[\"row_id\"] = row_ids\n",
    "    return w\n",
    "\n",
    "def row_text(w: pd.DataFrame, rid: int) -> str:\n",
    "    r = w[w[\"row_id\"]==rid].sort_values(\"left\")\n",
    "    return \" \".join(r[\"text\"].tolist()).strip()\n",
    "\n",
    "def pick_header_row(w: pd.DataFrame) -> Optional[int]:\n",
    "    if w.empty: return None\n",
    "    best, best_score = None, -1\n",
    "    for rid in w[\"row_id\"].unique().tolist()[:140]:\n",
    "        t = row_text(w, rid)\n",
    "        score = 0\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"date\"]): score += 3\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"description\"]): score += 3\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"amount\"]): score += 2\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"debit\"]): score += 2\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"credit\"]): score += 2\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"reference\"]): score += 1\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"channel\"]): score += 1\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"location\"]): score += 1\n",
    "        if _contains_any(t, HEADER_SYNONYMS[\"balance\"]): score += 1\n",
    "        if score > best_score:\n",
    "            best_score = score; best = rid\n",
    "    # m√°s permisivo: con 4 ya lo aceptamos\n",
    "    return best if best_score >= 4 else None\n",
    "\n",
    "def infer_columns_from_header(w: pd.DataFrame, header_rid: int) -> List[Tuple[float,float,str]]:\n",
    "    hdr = w[w[\"row_id\"]==header_rid].sort_values(\"left\").copy()\n",
    "    if hdr.empty: return []\n",
    "    hdr[\"x0\"] = hdr[\"left\"]\n",
    "    hdr[\"x1\"] = hdr[\"left\"] + hdr[\"width\"]\n",
    "    xs = hdr[[\"x0\",\"x1\",\"text\"]].values.tolist()\n",
    "\n",
    "    # gap threshold un poco menor para no ‚Äúpegar‚Äù headers distintos\n",
    "    groups = []\n",
    "    cur = [xs[0]]\n",
    "    for prev, nxt in zip(xs, xs[1:]):\n",
    "        gap = nxt[0] - prev[1]\n",
    "        if gap > 18:\n",
    "            groups.append(cur); cur = [nxt]\n",
    "        else:\n",
    "            cur.append(nxt)\n",
    "    groups.append(cur)\n",
    "\n",
    "    cols = []\n",
    "    for g in groups:\n",
    "        x0 = float(min(v[0] for v in g))\n",
    "        x1 = float(max(v[1] for v in g))\n",
    "        txt = \" \".join(v[2] for v in g).strip()\n",
    "        cols.append((x0,x1,txt))\n",
    "\n",
    "    cols = sorted(cols, key=lambda z: z[0])\n",
    "\n",
    "    fixed = []\n",
    "    for i,(x0,x1,txt) in enumerate(cols):\n",
    "        left = x0 - 10\n",
    "        right = x1 + 10\n",
    "        if i>0:\n",
    "            _, prev_x1, _ = cols[i-1]\n",
    "            left = (prev_x1 + x0)/2.0\n",
    "        if i < len(cols)-1:\n",
    "            next_x0, _, _ = cols[i+1]\n",
    "            right = (x1 + next_x0)/2.0\n",
    "        fixed.append((left,right,txt))\n",
    "    return fixed\n",
    "\n",
    "def map_header_to_field(htxt: str) -> Optional[str]:\n",
    "    ht = _norm(htxt)\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"date\"]): return \"date\"\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"time\"]): return \"time\"\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"description\"]): return \"description\"\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"reference\"]): return \"reference\"\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"location\"]): return \"location\"\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"channel\"]): return \"channel\"\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"balance\"]): return \"balance\"\n",
    "\n",
    "    # IMPORTANT: DEBIT/CREDIT antes que amount gen√©rico\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"debit\"]): return \"debit\"\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"credit\"]): return \"credit\"\n",
    "    if _contains_any(ht, HEADER_SYNONYMS[\"amount\"]): return \"amount\"\n",
    "    return None\n",
    "\n",
    "def assign_words_to_cols(w: pd.DataFrame, cols: List[Tuple[float,float,str]]) -> pd.DataFrame:\n",
    "    if w.empty or not cols:\n",
    "        w[\"col_id\"] = -1\n",
    "        return w\n",
    "    ww = w.copy()\n",
    "    ww[\"x_mid\"] = ww[\"left\"] + (ww[\"width\"]/2.0)\n",
    "    def col_for_x(x):\n",
    "        for i,(x0,x1,_) in enumerate(cols):\n",
    "            if x0 <= x <= x1:\n",
    "                return i\n",
    "        return -1\n",
    "    ww[\"col_id\"] = ww[\"x_mid\"].apply(col_for_x)\n",
    "    return ww\n",
    "\n",
    "def parse_table_image_to_transactions(table_img: Image.Image, bank: str, last4: str, statement_year: Optional[int]) -> Tuple[List[Dict[str,Any]], Dict[str,Any]]:\n",
    "    words = cluster_rows(ocr_data_df(table_img))\n",
    "    header_rid = pick_header_row(words)\n",
    "    if header_rid is None:\n",
    "        return [], {\"error\": \"No header detected\"}\n",
    "\n",
    "    cols = infer_columns_from_header(words, header_rid)\n",
    "\n",
    "    col_map = {}\n",
    "    for i,(_,_,htxt) in enumerate(cols):\n",
    "        f = map_header_to_field(htxt)\n",
    "        if f and f not in col_map:\n",
    "            col_map[f] = i\n",
    "\n",
    "    words2 = assign_words_to_cols(words, cols)\n",
    "\n",
    "    def cell_text(rid: int, colid: int) -> str:\n",
    "        c = words2[(words2[\"row_id\"]==rid) & (words2[\"col_id\"]==colid)].sort_values(\"left\")\n",
    "        return \" \".join(c[\"text\"].tolist()).strip()\n",
    "\n",
    "    txs = []\n",
    "    prev_tx = None\n",
    "    row_ids = sorted([rid for rid in words2[\"row_id\"].unique().tolist() if rid > header_rid])\n",
    "\n",
    "    skipped_no_amount = 0\n",
    "    continued = 0\n",
    "    kept = 0\n",
    "    samples_skipped = []\n",
    "\n",
    "    header_txt = row_text(words2, header_rid)\n",
    "\n",
    "    for rid in row_ids:\n",
    "        # extrae textos por columnas si existen\n",
    "        date_raw = cell_text(rid, col_map[\"date\"]) if \"date\" in col_map else \"\"\n",
    "        time = cell_text(rid, col_map[\"time\"]) if \"time\" in col_map else \"\"\n",
    "        desc = cell_text(rid, col_map[\"description\"]) if \"description\" in col_map else row_text(words2, rid)\n",
    "\n",
    "        # referencia / canal / etc\n",
    "        ref = cell_text(rid, col_map[\"reference\"]) if \"reference\" in col_map else \"\"\n",
    "        loc = cell_text(rid, col_map[\"location\"]) if \"location\" in col_map else \"\"\n",
    "        chan = cell_text(rid, col_map[\"channel\"]) if \"channel\" in col_map else \"\"\n",
    "\n",
    "        # montos: primero DEBIT/CREDIT, luego AMOUNT, luego fallback en texto\n",
    "        debit_raw = cell_text(rid, col_map[\"debit\"]) if \"debit\" in col_map else \"\"\n",
    "        credit_raw = cell_text(rid, col_map[\"credit\"]) if \"credit\" in col_map else \"\"\n",
    "        amt_raw = cell_text(rid, col_map[\"amount\"]) if \"amount\" in col_map else \"\"\n",
    "\n",
    "        # fecha normalizada: si no hay date_raw, buscar en la fila completa\n",
    "        date_iso = normalize_date_str(date_raw, statement_year)\n",
    "        if not date_iso:\n",
    "            date_iso = date_from_row_fallback(row_text(words2, rid), statement_year)\n",
    "\n",
    "        # monto: si hay cr√©dito/d√©bito, √∫salo con signo\n",
    "        amount = None\n",
    "        currency = infer_currency((debit_raw or \"\") + \" \" + (credit_raw or \"\") + \" \" + (amt_raw or \"\") + \" \" + (desc or \"\"), default=DEFAULT_CURRENCY)\n",
    "\n",
    "        deb = parse_amount_string(debit_raw) if debit_raw else None\n",
    "        cre = parse_amount_string(credit_raw) if credit_raw else None\n",
    "\n",
    "        if cre is not None and (deb is None or abs(cre) >= 0.01):\n",
    "            amount = abs(cre)  # cr√©dito positivo\n",
    "        elif deb is not None and (cre is None or abs(deb) >= 0.01):\n",
    "            amount = -abs(deb) # d√©bito negativo\n",
    "        else:\n",
    "            # monto general\n",
    "            amount, _cur = parse_amount_and_currency(amt_raw, desc, default_currency=DEFAULT_CURRENCY)\n",
    "            if amount is None:\n",
    "                # fallback: buscar monto en texto completo de la fila\n",
    "                amount = parse_amount_from_text_fallback(row_text(words2, rid))\n",
    "\n",
    "        row_full_txt = row_text(words2, rid)\n",
    "\n",
    "        # CONTINUACI√ìN: si no hay monto y no hay fecha, pero hay texto -> pega al anterior\n",
    "        if (not date_iso) and (amount is None) and desc and prev_tx is not None:\n",
    "            prev_tx[\"description\"] = (prev_tx[\"description\"] + \" \" + desc).strip()\n",
    "            if ref and not prev_tx.get(\"reference\"): prev_tx[\"reference\"] = ref\n",
    "            if loc and not prev_tx.get(\"location\"): prev_tx[\"location\"] = loc\n",
    "            if chan and not prev_tx.get(\"channel\"): prev_tx[\"channel\"] = chan\n",
    "            continued += 1\n",
    "            continue\n",
    "\n",
    "        # si no hay monto, intenta a√∫n una √∫ltima vez: por texto completo\n",
    "        if amount is None:\n",
    "            amount = parse_amount_from_text_fallback(row_full_txt)\n",
    "\n",
    "        if amount is None:\n",
    "            skipped_no_amount += 1\n",
    "            if len(samples_skipped) < DEBUG_SHOW_SAMPLES:\n",
    "                samples_skipped.append(row_full_txt)\n",
    "            continue\n",
    "\n",
    "        tx = {\n",
    "            \"bank\": bank,\n",
    "            \"account_last4\": last4,\n",
    "            \"date\": date_iso,               # YYYY-MM-DD o ''\n",
    "            \"time\": time,\n",
    "            \"amount\": amount,\n",
    "            \"currency\": currency,\n",
    "            \"movement_type\": classify_movement_type(desc),\n",
    "            \"reference\": ref,\n",
    "            \"merchant\": \"\",\n",
    "            \"location\": loc,\n",
    "            \"channel\": chan,\n",
    "            \"description\": desc if desc else row_full_txt,\n",
    "            \"id\": uuid.uuid4().hex,\n",
    "        }\n",
    "        txs.append(tx)\n",
    "        prev_tx = tx\n",
    "        kept += 1\n",
    "\n",
    "    dbg = {\n",
    "        \"header_row_id\": header_rid,\n",
    "        \"header_text\": header_txt,\n",
    "        \"col_map\": col_map,\n",
    "        \"n_cols\": len(cols),\n",
    "        \"rows_total_after_header\": len(row_ids),\n",
    "        \"kept\": kept,\n",
    "        \"continued\": continued,\n",
    "        \"skipped_no_amount\": skipped_no_amount,\n",
    "        \"skipped_samples\": samples_skipped,\n",
    "    }\n",
    "    return txs, dbg\n",
    "\n",
    "def fullpage_fallback_transactions(page_img: Image.Image, bank: str, last4: str, statement_year: Optional[int]) -> Tuple[List[Dict[str,Any]], Dict[str,Any]]:\n",
    "    txs, dbg = parse_table_image_to_transactions(page_img, bank, last4, statement_year)\n",
    "    dbg[\"fullpage_fallback\"] = True\n",
    "    return txs, dbg\n",
    "\n",
    "# ===========================\n",
    "# MAIN\n",
    "# ===========================\n",
    "def process_pdfs(pdf_dir: str, output_xlsx: str) -> Dict[str, Any]:\n",
    "    pdf_paths = sorted(glob.glob(str(Path(pdf_dir) / \"*.pdf\")))\n",
    "    if not pdf_paths:\n",
    "        raise FileNotFoundError(f\"No PDFs en: {pdf_dir}\")\n",
    "\n",
    "    all_txs = []\n",
    "    all_dbg = []\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        pdf_name = Path(pdf_path).name\n",
    "\n",
    "        pages, used_pw, method = render_pdf_pages(pdf_path, PASSWORDS, DPI, MAX_PAGES)\n",
    "        if not pages:\n",
    "            print(f\"\\nüìÑ {pdf_name} -> ‚ùå No se pudo renderizar (clave o poppler).\")\n",
    "            continue\n",
    "\n",
    "        # OCR de primera p√°gina para: banco, last4, a√±o del extracto\n",
    "        first_txt = \"\"\n",
    "        try:\n",
    "            first_txt = pytesseract.image_to_string(pages[0].convert(\"L\"), lang=LANG_OCR, config=TESS_CONFIG)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        bank, last4 = detect_bank_and_last4(first_txt)\n",
    "        statement_year = infer_statement_year(first_txt)\n",
    "\n",
    "        print(f\"\\nüìÑ {pdf_name} | pages={len(pages)} | render={method}{' (pw)' if used_pw else ''} | bank={bank} | last4={last4 or 'NA'} | year={statement_year or 'NA'}\")\n",
    "\n",
    "        total_tables_pdf = 0\n",
    "        kept_pdf = 0\n",
    "\n",
    "        for p_idx, page_img in enumerate(pages, start=1):\n",
    "            dets = []\n",
    "            try:\n",
    "                dets = detect_tables(page_img, score_thr=DETECTION_SCORE_THRESHOLD)\n",
    "                if len(dets) == 0:\n",
    "                    dets = detect_tables(page_img, score_thr=SECONDARY_THRESHOLD)\n",
    "            except:\n",
    "                dets = []\n",
    "\n",
    "            print(f\"  - page {p_idx}: tablas_detectadas={len(dets)} (thr={DETECTION_SCORE_THRESHOLD}/{SECONDARY_THRESHOLD})\")\n",
    "            total_tables_pdf += len(dets)\n",
    "\n",
    "            page_got_rows = 0\n",
    "            for t_idx, d in enumerate(dets, start=1):\n",
    "                x0,y0,x1,y1 = d[\"bbox\"]\n",
    "                # padding para no cortar encabezados o √∫ltima columna\n",
    "                x0,y0,x1,y1 = pad_bbox((x0,y0,x1,y1), page_img.size[0], page_img.size[1], pad=18)\n",
    "                crop = page_img.crop((x0,y0,x1,y1))\n",
    "\n",
    "                txs, dbg = parse_table_image_to_transactions(crop, bank, last4, statement_year)\n",
    "\n",
    "                if DEBUG_TABLES:\n",
    "                    print(f\"    table {t_idx}: score={d['score']:.2f} bbox={(x0,y0,x1,y1)}\")\n",
    "                    if \"error\" in dbg:\n",
    "                        print(f\"      ‚ùå {dbg['error']}\")\n",
    "                    else:\n",
    "                        print(f\"      header: {dbg['header_text']}\")\n",
    "                        print(f\"      col_map: {dbg['col_map']}\")\n",
    "                        print(f\"      rows(after header)={dbg['rows_total_after_header']} kept={dbg['kept']} cont={dbg['continued']} skipped_no_amount={dbg['skipped_no_amount']}\")\n",
    "                        if dbg.get(\"skipped_samples\"):\n",
    "                            for i,smp in enumerate(dbg[\"skipped_samples\"], 1):\n",
    "                                print(f\"        sample_skipped_{i}: {smp[:180]}\")\n",
    "\n",
    "                if txs:\n",
    "                    for tx in txs:\n",
    "                        tx[\"source_pdf\"] = pdf_name\n",
    "                        tx[\"source_page\"] = p_idx\n",
    "                        tx[\"source_table\"] = t_idx\n",
    "                    all_txs.extend(txs)\n",
    "                    page_got_rows += len(txs)\n",
    "                    kept_pdf += len(txs)\n",
    "                    all_dbg.append({\"pdf\": pdf_name, \"page\": p_idx, \"table\": t_idx, **dbg})\n",
    "\n",
    "            # fallback: si no detect√≥ nada o no sac√≥ filas, intenta p√°gina completa\n",
    "            if (len(dets) == 0) or (page_got_rows == 0):\n",
    "                fallback_txs, fdbg = fullpage_fallback_transactions(page_img, bank, last4, statement_year)\n",
    "                if DEBUG_TABLES and \"error\" not in fdbg:\n",
    "                    print(f\"    fallback full-page: kept={fdbg.get('kept',0)} skipped_no_amount={fdbg.get('skipped_no_amount',0)} col_map={fdbg.get('col_map',{})}\")\n",
    "                if fallback_txs:\n",
    "                    for tx in fallback_txs:\n",
    "                        tx[\"source_pdf\"] = pdf_name\n",
    "                        tx[\"source_page\"] = p_idx\n",
    "                        tx[\"source_table\"] = 0\n",
    "                    all_txs.extend(fallback_txs)\n",
    "                    kept_pdf += len(fallback_txs)\n",
    "                    all_dbg.append({\"pdf\": pdf_name, \"page\": p_idx, \"table\": 0, **fdbg})\n",
    "                    print(f\"    ‚úÖ fallback full-page: +{len(fallback_txs)} filas\")\n",
    "\n",
    "        print(f\"  => total tablas detectadas en PDF: {total_tables_pdf} | filas_kept_pdf={kept_pdf}\")\n",
    "\n",
    "    tx_df = pd.DataFrame(all_txs)\n",
    "\n",
    "    # ---- LIMPIEZA / REGLAS ----\n",
    "    if not tx_df.empty:\n",
    "        tx_df[\"amount\"] = pd.to_numeric(tx_df[\"amount\"], errors=\"coerce\")\n",
    "        tx_df = tx_df[tx_df[\"amount\"].notna()].copy()\n",
    "\n",
    "        # fecha final: NO borres filas sin fecha; solo normaliza donde exista\n",
    "        tx_df[\"date\"] = pd.to_datetime(tx_df[\"date\"], errors=\"coerce\").dt.date.astype(str)\n",
    "        tx_df.loc[tx_df[\"date\"] == \"NaT\", \"date\"] = \"\"\n",
    "\n",
    "    # columnas objetivo\n",
    "    target_cols = [\"bank\",\"account_last4\",\"date\",\"time\",\"amount\",\"currency\",\"movement_type\",\"reference\",\"merchant\",\"location\",\"channel\",\"description\",\"id\"]\n",
    "    for c in target_cols:\n",
    "        if c not in tx_df.columns:\n",
    "            tx_df[c] = \"\"\n",
    "\n",
    "    # ordenar y dejar solo 1 sheet\n",
    "    tx_df = tx_df[target_cols + [\"source_pdf\",\"source_page\",\"source_table\"]] if \"source_pdf\" in tx_df.columns else tx_df[target_cols]\n",
    "\n",
    "    # limpiar caracteres ilegales excel\n",
    "    for c in tx_df.columns:\n",
    "        if tx_df[c].dtype == object:\n",
    "            tx_df[c] = tx_df[c].apply(sanitize_excel_str)\n",
    "\n",
    "    with pd.ExcelWriter(output_xlsx, engine=\"openpyxl\") as writer:\n",
    "        tx_df.to_excel(writer, index=False, sheet_name=\"movimientos\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Excel generado: {output_xlsx}\")\n",
    "    return {\"pdfs\": len(pdf_paths), \"rows\": int(tx_df.shape[0])}\n",
    "\n",
    "summary = process_pdfs(PDF_DIR, OUTPUT_XLSX)\n",
    "print(\"RESUMEN:\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PruebaXolit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
